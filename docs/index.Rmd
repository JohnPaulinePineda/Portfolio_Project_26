---
title: "R : Estimating Deviance Scores Using Isolation Forest-Based Outlier Detection Algorithms"
author: "John Pauline Pineda"
date: "February 11, 2023"
output: 
  html_document:
    toc: true
    toc_depth: 3
    theme: readable
    highlight: tango
    css: doc.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=15, fig.height=10)
```
# **1. Table of Contents**
|
| This document implements isolation forest-based outlier detection algorithms for estimating scores for deviant points using various helpful packages in <mark style="background-color: #CCECFF">**R**</mark>.    
|
##  1.1 Sample Data
|
| The <mark style="background-color: #EEEEEE;color: #FF0000">**Satellite**</mark>  dataset from the <mark style="background-color: #CCECFF">**isotree**</mark> and <mark style="background-color: #CCECFF">**mlbench**</mark> packages was used for this illustrated example.
|
| Preliminary dataset assessment:
|
| **[A]** 6435 rows (observations)
| 
| **[B]** 37 columns (variables)
|      **[B.1]** 1/37 label = <span style="color: #FF0000">Status</span> variable (factor)
|             **[B.1.1]** Category 1 = <span style="color: #FF0000">Status=Outlier</span> 
|             **[B.1.2]** Category 2 = <span style="color: #FF0000">Status=Valid</span> 
|      **[B.2]** 36/37 descriptors = 36/36 numeric
|     
|  
```{r section_1.1, warning=FALSE, message=FALSE}
##################################
# Loading R libraries
##################################
library(AppliedPredictiveModeling)
library(caret)
library(rpart)
library(lattice)
library(dplyr)
library(tidyr)
library(moments)
library(skimr)
library(RANN)
library(pls)
library(corrplot)
library(tidyverse)
library(lares)
library(DMwR)
library(gridExtra)
library(rattle)
library(RColorBrewer)
library(stats)
library(Hmisc)
library(isotree)
library(mlbench)
library(MLmetrics)

##################################
# Loading source and
# formulating the train set
##################################
data(Satellite)
Satellite <- as.data.frame(Satellite)

Satellite_Reference <- Satellite

##################################
# Creating outlier labels
##################################
Satellite_Outlier_Label <- Satellite$classes %in% c("damp grey soil",
                                                    "cotton crop", 
                                                    "vegetation stubble")

##################################
# Formulating an unlabeled dataset
##################################
Satellite <- Satellite[, names(Satellite)[names(Satellite) != "classes"]]
Satellite$Status <- ifelse(Satellite_Outlier_Label==TRUE,
                            "Outlier",
                            "Valid")
Satellite$Status <- as.factor(Satellite$Status)

##################################
# Performing a general exploration of the data set
##################################
dim(Satellite)
str(Satellite)
summary(Satellite)
describe(Satellite)

##################################
# Formulating a data type assessment summary
##################################
PDA <- Satellite
(PDA.Summary <- data.frame(
  Column.Index=c(1:length(names(PDA))),
  Column.Name= names(PDA), 
  Column.Type=sapply(PDA, function(x) class(x)), 
  row.names=NULL)
)
```
##  1.2 Data Quality Assessment
|
| Data quality assessment:
|
| **[A]** No missing observations noted for any variable.
|
| **[B]** No low variance observed for any variable with First.Second.Mode.Ratio>5.
|
| **[C]** No low variance observed for any variable with Unique.Count.Ratio<0.01.
|
| **[D]** No high skewness observed for any variable with Skewness>3 or Skewness<(-3).
|
```{r section_1.2, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
DQA <- Satellite
DQA.Descriptors <- DQA[, names(DQA)[names(DQA) != "Status"]]

##################################
# Formulating an overall data quality assessment summary
##################################
(DQA.Summary <- data.frame(
  Column.Index=c(1:length(names(DQA))),
  Column.Name= names(DQA),
  Column.Type=sapply(DQA, function(x) class(x)),
  Row.Count=sapply(DQA, function(x) nrow(DQA)),
  NA.Count=sapply(DQA,function(x)sum(is.na(x))),
  Fill.Rate=sapply(DQA,function(x)format(round((sum(!is.na(x))/nrow(DQA)),3),nsmall=3)),
  row.names=NULL)
)

##################################
# Listing all descriptors
##################################
DQA.Descriptors <- DQA

##################################
# Listing all numeric Descriptors
##################################
DQA.Descriptors.Numeric <- DQA.Descriptors[,sapply(DQA.Descriptors, is.numeric)]

if (length(names(DQA.Descriptors.Numeric))>0) {
    print(paste0("There are ",
               (length(names(DQA.Descriptors.Numeric))),
               " numeric descriptor variable(s)."))
} else {
  print("There are no numeric descriptor variables.")
}

##################################
# Listing all factor Descriptors
##################################
DQA.Descriptors.Factor <- DQA.Descriptors[,sapply(DQA.Descriptors, is.factor)]

if (length(names(DQA.Descriptors.Factor))>0) {
    print(paste0("There are ",
               (length(names(DQA.Descriptors.Factor))),
               " factor descriptor variable(s)."))
} else {
  print("There are no factor descriptor variables.")
}

##################################
# Formulating a data quality assessment summary for factor Descriptors
##################################
if (length(names(DQA.Descriptors.Factor))>0) {

  ##################################
  # Formulating a function to determine the first mode
  ##################################
  FirstModes <- function(x) {
    ux <- unique(na.omit(x))
    tab <- tabulate(match(x, ux))
    ux[tab == max(tab)]
  }

  ##################################
  # Formulating a function to determine the second mode
  ##################################
  SecondModes <- function(x) {
    ux <- unique(na.omit(x))
    tab <- tabulate(match(x, ux))
    fm = ux[tab == max(tab)]
    sm = x[!(x %in% fm)]
    usm <- unique(sm)
    tabsm <- tabulate(match(sm, usm))
    ifelse(is.na(usm[tabsm == max(tabsm)])==TRUE,
           return("x"),
           return(usm[tabsm == max(tabsm)]))
  }

  (DQA.Descriptors.Factor.Summary <- data.frame(
  Column.Name= names(DQA.Descriptors.Factor),
  Column.Type=sapply(DQA.Descriptors.Factor, function(x) class(x)),
  Unique.Count=sapply(DQA.Descriptors.Factor, function(x) length(unique(x))),
  First.Mode.Value=sapply(DQA.Descriptors.Factor, function(x) as.character(FirstModes(x)[1])),
  Second.Mode.Value=sapply(DQA.Descriptors.Factor, function(x) as.character(SecondModes(x)[1])),
  First.Mode.Count=sapply(DQA.Descriptors.Factor, function(x) sum(na.omit(x) == FirstModes(x)[1])),
  Second.Mode.Count=sapply(DQA.Descriptors.Factor, function(x) sum(na.omit(x) == SecondModes(x)[1])),
  Unique.Count.Ratio=sapply(DQA.Descriptors.Factor, function(x) format(round((length(unique(x))/nrow(DQA.Descriptors.Factor)),3), nsmall=3)),
  First.Second.Mode.Ratio=sapply(DQA.Descriptors.Factor, function(x) format(round((sum(na.omit(x) == FirstModes(x)[1])/sum(na.omit(x) == SecondModes(x)[1])),3), nsmall=3)),
  row.names=NULL)
  )

}

##################################
# Formulating a data quality assessment summary for numeric Descriptors
##################################
if (length(names(DQA.Descriptors.Numeric))>0) {

  ##################################
  # Formulating a function to determine the first mode
  ##################################
  FirstModes <- function(x) {
    ux <- unique(na.omit(x))
    tab <- tabulate(match(x, ux))
    ux[tab == max(tab)]
  }

  ##################################
  # Formulating a function to determine the second mode
  ##################################
  SecondModes <- function(x) {
    ux <- unique(na.omit(x))
    tab <- tabulate(match(x, ux))
    fm = ux[tab == max(tab)]
    sm = na.omit(x)[!(na.omit(x) %in% fm)]
    usm <- unique(sm)
    tabsm <- tabulate(match(sm, usm))
    ifelse(is.na(usm[tabsm == max(tabsm)])==TRUE,
           return(0.00001),
           return(usm[tabsm == max(tabsm)]))
  }

  (DQA.Descriptors.Numeric.Summary <- data.frame(
  Column.Name= names(DQA.Descriptors.Numeric),
  Column.Type=sapply(DQA.Descriptors.Numeric, function(x) class(x)),
  Unique.Count=sapply(DQA.Descriptors.Numeric, function(x) length(unique(x))),
  Unique.Count.Ratio=sapply(DQA.Descriptors.Numeric, function(x) format(round((length(unique(x))/nrow(DQA.Descriptors.Numeric)),3), nsmall=3)),
  First.Mode.Value=sapply(DQA.Descriptors.Numeric, function(x) format(round((FirstModes(x)[1]),3),nsmall=3)),
  Second.Mode.Value=sapply(DQA.Descriptors.Numeric, function(x) format(round((SecondModes(x)[1]),3),nsmall=3)),
  First.Mode.Count=sapply(DQA.Descriptors.Numeric, function(x) sum(na.omit(x) == FirstModes(x)[1])),
  Second.Mode.Count=sapply(DQA.Descriptors.Numeric, function(x) sum(na.omit(x) == SecondModes(x)[1])),
  First.Second.Mode.Ratio=sapply(DQA.Descriptors.Numeric, function(x) format(round((sum(na.omit(x) == FirstModes(x)[1])/sum(na.omit(x) == SecondModes(x)[1])),3), nsmall=3)),
  Minimum=sapply(DQA.Descriptors.Numeric, function(x) format(round(min(x,na.rm = TRUE),3), nsmall=3)),
  Mean=sapply(DQA.Descriptors.Numeric, function(x) format(round(mean(x,na.rm = TRUE),3), nsmall=3)),
  Median=sapply(DQA.Descriptors.Numeric, function(x) format(round(median(x,na.rm = TRUE),3), nsmall=3)),
  Maximum=sapply(DQA.Descriptors.Numeric, function(x) format(round(max(x,na.rm = TRUE),3), nsmall=3)),
  Skewness=sapply(DQA.Descriptors.Numeric, function(x) format(round(skewness(x,na.rm = TRUE),3), nsmall=3)),
  Kurtosis=sapply(DQA.Descriptors.Numeric, function(x) format(round(kurtosis(x,na.rm = TRUE),3), nsmall=3)),
  Percentile25th=sapply(DQA.Descriptors.Numeric, function(x) format(round(quantile(x,probs=0.25,na.rm = TRUE),3), nsmall=3)),
  Percentile75th=sapply(DQA.Descriptors.Numeric, function(x) format(round(quantile(x,probs=0.75,na.rm = TRUE),3), nsmall=3)),
  row.names=NULL)
  )

}

##################################
# Identifying potential data quality issues
##################################

##################################
# Checking for missing observations
##################################
if ((nrow(DQA.Summary[DQA.Summary$NA.Count>0,]))>0){
  print(paste0("Missing observations noted for ",
               (nrow(DQA.Summary[DQA.Summary$NA.Count>0,])),
               " variable(s) with NA.Count>0 and Fill.Rate<1.0."))
  DQA.Summary[DQA.Summary$NA.Count>0,]
} else {
  print("No missing observations noted.")
}

##################################
# Checking for zero or near-zero variance Descriptors
##################################
if (length(names(DQA.Descriptors.Factor))==0) {
  print("No factor descriptors noted.")
} else if (nrow(DQA.Descriptors.Factor.Summary[as.numeric(as.character(DQA.Descriptors.Factor.Summary$First.Second.Mode.Ratio))>5,])>0){
  print(paste0("Low variance observed for ",
               (nrow(DQA.Descriptors.Factor.Summary[as.numeric(as.character(DQA.Descriptors.Factor.Summary$First.Second.Mode.Ratio))>5,])),
               " factor variable(s) with First.Second.Mode.Ratio>5."))
  DQA.Descriptors.Factor.Summary[as.numeric(as.character(DQA.Descriptors.Factor.Summary$First.Second.Mode.Ratio))>5,]
} else {
  print("No low variance factor descriptors due to high first-second mode ratio noted.")
}

if (length(names(DQA.Descriptors.Numeric))==0) {
  print("No numeric descriptors noted.")
} else if (nrow(DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$First.Second.Mode.Ratio))>5,])>0){
  print(paste0("Low variance observed for ",
               (nrow(DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$First.Second.Mode.Ratio))>5,])),
               " numeric variable(s) with First.Second.Mode.Ratio>5."))
  DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$First.Second.Mode.Ratio))>5,]
} else {
  print("No low variance numeric descriptors due to high first-second mode ratio noted.")
}

if (length(names(DQA.Descriptors.Numeric))==0) {
  print("No numeric descriptors noted.")
} else if (nrow(DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Unique.Count.Ratio))<0.01,])>0){
  print(paste0("Low variance observed for ",
               (nrow(DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Unique.Count.Ratio))<0.01,])),
               " numeric variable(s) with Unique.Count.Ratio<0.01."))
  DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Unique.Count.Ratio))<0.01,]
} else {
  print("No low variance numeric descriptors due to low unique count ratio noted.")
}

##################################
# Checking for skewed Descriptors
##################################
if (length(names(DQA.Descriptors.Numeric))==0) {
  print("No numeric descriptors noted.")
} else if (nrow(DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Skewness))>3 |
                                               as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Skewness))<(-3),])>0){
  print(paste0("High skewness observed for ",
  (nrow(DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Skewness))>3 |
                                               as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Skewness))<(-3),])),
  " numeric variable(s) with Skewness>3 or Skewness<(-3)."))
  DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Skewness))>3 |
                                 as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Skewness))<(-3),]
} else {
  print("No skewed numeric descriptors noted.")
}

```

##  1.3 Data Preprocessing

###  1.3.1 Centering and Scaling
|
| Centering and Scaling data assessment:
|
| **[A]** To maintain an objective comparison across the different descriptors, centering and scaling transformation was applied on the numeric variables. The <span style="color: #0000FF">center</span> method from the <mark style="background-color: #CCECFF">**caret**</mark> package was implemented which subtracts the average value of a numeric variable to all the values. As a result of centering, the variables had zero mean values. In addition, the <span style="color: #0000FF">scale</span> method, also from the <mark style="background-color: #CCECFF">**caret**</mark> package, was applied which performs a center transformation with each value of the variable divided by its standard deviation. Scaling the data coerced the values to have a common standard deviation of one.
|
```{r section_1.3.1, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
DPA <- Satellite

##################################
# Listing all descriptors
##################################
DPA.Descriptors <- DPA[, names(DPA)[names(DPA) != "Status"]]

##################################
# Listing all numeric descriptors
##################################
DPA.Descriptors.Numeric <- DPA.Descriptors[,sapply(DPA.Descriptors, is.numeric)]

##################################
# Applying a center and scale data transformation
##################################
DPA.Descriptors.Numeric_CenteredScaled <- preProcess(DPA.Descriptors.Numeric, 
                                                     method = c("center","scale"))
DPA.Descriptors.Numeric_CenteredScaledTransformed <- predict(DPA.Descriptors.Numeric_CenteredScaled, DPA.Descriptors.Numeric)
row.names(DPA.Descriptors.Numeric_CenteredScaledTransformed) <- NULL

```

###  1.3.2 Dimensionality Reduction
|
| Data transformation assessment:
|
| **[A]** Considering the high dimensional nature of the dataset, Principal Component Analysis (PCA) was applied to summarize the information content from the 36 descriptors by means of a smaller set of summary indices composed of the first two principal components, enabling a more efficient visualization and analysis.
|
```{r section_1.3.2, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
Status <- Satellite$Status
Satellite_Transformed <- cbind(DPA.Descriptors.Numeric_CenteredScaledTransformed,
                               Satellite$Status)

DR <- as.data.frame(Satellite_Transformed)

DR.Numeric <- DR[,sapply(DR, is.numeric)]

##################################
# Performing PCA
##################################
DR_PCA <- prcomp(DR.Numeric)

##################################
# Consolidating the PCA components
##################################
rownames(DR_PCA$x) <- NULL
DR_PCA$x <- as.data.frame(DR_PCA$x)
(DR_PCA_FULL <- cbind(DR_PCA$x, Status))

##################################
# Creating a data subset only containing
# the first two principal components
##################################
(DR_PCA_SUBSET <- DR_PCA_FULL[,c("Status",
                                "PC1",
                                "PC2",
                                "PC3",
                                "PC4",
                                "PC5",
                                "PC6",
                                "PC7",
                                "PC8",
                                "PC9",
                                "PC10")])

```

###  1.3.3 Pre-Processed Dataset
|
| Preliminary dataset assessment:
|
| **[A]** 6435 rows (observations)
| 
| **[B]** 4 columns (variables)
|      **[B.1]** 1/4 label = <span style="color: #FF0000">labs</span> variable (factor)
|             **[B.1.1]** Category 1 = <span style="color: #FF0000">Status=Outlier</span> 
|             **[B.1.2]** Category 2 = <span style="color: #FF0000">Status=Valid</span> 
|      **[B.2]** 3/4 descriptors = 3/3 numeric
|             **[B.2.1]** <span style="color: #FF0000">PC1</span> variable
|             **[B.2.2]** <span style="color: #FF0000">PC2</span> variable 
| 
| **[C]** Pre-processing actions applied:
|      **[C.1]** Centering and scaling applied to improve data quality
|      **[C.2]** PCA transformation to reduce the number of features into a workable subset
| 
```{r section_1.3.3, warning=FALSE, message=FALSE}
##################################
# Gathering deascriptive statistics
##################################
(DR_PCA_SUBSET_Skimmed <- skim(as.data.frame(DR_PCA_SUBSET)))

```

## 1.4 Data Exploration
|
| Exploratory data analysis:
|
| **[A]** From a univariate sense, principal component descriptors demonstrated various relationship patterns across the different levels of the <span style="color: #FF0000">Status</span> variable.
|             **[A.1.1]** <span style="color: #FF0000">Status=Outlier</span> and <span style="color: #FF0000">Status=Valid</span> cases are differentially expressed in terms of the <span style="color: #FF0000">PC1</span>, <span style="color: #FF0000">PC2</span> and <span style="color: #FF0000">PC3</span> variables.
|             **[A.1.2]** <span style="color: #FF0000">Status=Outlier</span> showed a wider range as compared to the <span style="color: #FF0000">Status=Outlier</span> cases are in terms of the <span style="color: #FF0000">PC5</span>, <span style="color: #FF0000">PC7</span> and <span style="color: #FF0000">PC9</span> variables.
|
| **[B]** From a multivariate sense, pairwise analysis between the principal component descriptors demonstrated the following observations between the <span style="color: #FF0000">Status</span> variable levels.
|             **[B.1.1]** Overlapping orthogonal clustering patterns observed between the <span style="color: #FF0000">Status=Outlier</span> and <span style="color: #FF0000">Status=Valid</span> cases with the pairwise comparison across the <span style="color: #FF0000">PC1</span> and <span style="color: #FF0000">PC2</span> variables.
|             **[B.1.2]** Overlapping concentric clustering patterns observed between the <span style="color: #FF0000">Status=Outlier</span> and <span style="color: #FF0000">Status=Valid</span> cases with the pairwise comparison across the <span style="color: #FF0000">PC5</span>, <span style="color: #FF0000">PC7</span> and <span style="color: #FF0000">PC9</span> variables.
|
| **[C]** To better visualize deviance scores through a heatmap, the subsequent analysis will be conducted using the <span style="color: #FF0000">PC1</span> and <span style="color: #FF0000">PC2</span> variables.
|
```{r section_1.4, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
EDA <- as.data.frame(DR_PCA_SUBSET)

EDA$Algorithm <- rep("PCA-BASE",nrow(EDA))

##################################
# Creating a function to define the
# range of descriptors for plotting
##################################

featurePlotRange <- function(start,end){

  ##################################
  # Listing all Descriptors
  ##################################
  EDA.Descriptors <- EDA[,start:end]
  EDA.Descriptors.Numeric <- EDA.Descriptors[,sapply(EDA.Descriptors, is.numeric)]

  ##################################
  # Formulating the box plots
  ##################################
  featurePlotResult <- featurePlot(x = EDA.Descriptors.Numeric,
            y = EDA$Status,
            plot = "box",
            scales = list(x = list(relation="free", rot = 90),
                          y = list(relation="free")),
            adjust = 1.5,
            pch = "|",
            layout = c(2,ncol(EDA.Descriptors.Numeric)/2))

  return(featurePlotResult)

}

##################################
# Creating univariate plots
# for the principal components
# grouped by status
##################################
featurePlotRange(1,11)

##################################
# Creating multivariate plots
# for the principal components
# grouped by status
##################################
splom(~EDA[,sapply(EDA, is.numeric)],
      groups = EDA$Status,
      pch = 16,
      cex = 1,
      alpha = 0.45,
      auto.key = list(points = TRUE, space = "top"),
      main = "Pairwise Scatterplots of Principal Component Descriptors",
      xlab = "PCA" )

DR_PCA_SUBSET <- DR_PCA_FULL[,c("Status",
                                "PC1",
                                "PC2")]

describe(DR_PCA_SUBSET)

EDA <- as.data.frame(DR_PCA_SUBSET)

EDA$Algorithm <- rep("PCA-BASE",nrow(EDA))

##################################
# Creating multivariate plots
# for the principal components
# grouped by status
##################################
splom(~EDA[,sapply(EDA, is.numeric)],
      groups = EDA$Status,
      pch = 16,
      cex = 2,
      alpha = 0.45,
      auto.key = list(points = TRUE, space = "top"),
      main = "Pairwise Scatterplots of Principal Component Descriptors",
      xlab = "PCA" )

```

## 1.5 Isolation Forest-Based Outlier Detection

###  1.5.1. Isolation Forest (IF)
|
| **[A]** The Isolation Forest algorithm was implemented only for the <span style="color: #FF0000">PC1</span> and <span style="color: #FF0000">PC2</span> principal component descriptors using the <mark style="background-color: #CCECFF">**isotree**</mark> package.  
|
| **[B]** The algorithm contains 3 hyperparameters:
|      **[B.1]** <span style="color: #FF0000">ndims</span> = number of columns to combine to produce a split held constant at a value of 1.
|      **[B.2]** <span style="color: #FF0000">ntrees</span> = number of binary trees to build for the model held constant at a value of 100.
|      **[B.3]** <span style="color: #FF0000">missing_action</span> = method of handling missing data at both fitting and prediction time held constant at a value of "FAIL".
|
| **[C]** Using the label information from the <span style="color: #FF0000">Status</span> variable defined prior to the analysis, the algorithm was able to sufficiently discriminate between <span style="color: #FF0000">Status=Outlier</span> and <span style="color: #FF0000">Status=Valid</span>, as demonstrated by their differentially expressed deviance score densities.
|      **[C.1]** ROC Curve AUC = 0.76056
|
```{r section_1.5.1, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
OD <- as.data.frame(DR_PCA_SUBSET[,c(2:3)])

##################################
# Creating a function to create 
# a heatmap of the deviance scores
##################################
Point_Range = seq(-15, 15, .1)
Space_Range <- expand.grid(PC1=Point_Range, PC2=Point_Range)
Plot_Space_Range <- function(Deviance_Scores, Title, cex.main = 1.4) {
    image(Point_Range, 
          Point_Range, 
          matrix(Deviance_Scores, 
                 nrow = length(Point_Range)),
          col = rev(heat.colors(100)),
          main = Title, 
          cex.main = cex.main,
          xlim = c(-15, 15), 
          ylim = c(-15, 15),
          xlab = "PC1", 
          ylab = "PC2")
    par(new = TRUE)
    plot(OD, 
         type = "p",
         lwd = 10,
         xlim = c(-15, 15), 
         ylim = c(-15, 15),
         col = "#0000001A",
         axes = FALSE, 
         main = "",
         xlab = "", 
         ylab = "")
}

##################################
# Implementing the IF Algorithm
##################################
OD_IF <- isolation.forest(OD, 
                          ndim=1, 
                          ntrees=100, 
                          missing_action="fail")

##################################
# Determining the outlier scores
# for the deviant points
# applied to the entire space range
##################################
OD_IF_DevianceScores <- predict(OD_IF, Space_Range)

##################################
# Plotting the heatmap
# for the deviant points
##################################
par(mar = c(2.5,2.2,2,2.5))
Plot_Space_Range(OD_IF_DevianceScores,
                 "Deviance Scores : Isolation Forest",
                 1.0)

##################################
# Determining the outlier scores
# for the deviant points
# applied to the dataset
##################################
OD_IF_PredictedScores <- predict(OD_IF, OD)

##################################
# Exploring the outlier scores
# between the valid and outlier points
##################################
max(OD_IF_PredictedScores)
min(OD_IF_PredictedScores)

OD_IF_Summary <- DR_PCA_SUBSET

OD_IF_Summary$Scores <- OD_IF_PredictedScores
OD_IF_Summary$Label <- rep("IF", nrow(OD_IF_Summary))

densityplot( ~ Scores | Label,
            data = OD_IF_Summary,
            groups = Status,
            xlab = "Deviance Scores",
            ylab = "Density",
            auto.key = list(columns = (length(levels(OD_IF_Summary$Status)))))

##################################
# Determining the apparent 
# discrimination performance
# of the IF Algorithm
##################################
Status <- ifelse(OD_IF_Summary$Status=="Valid",0,1)

(OD_IF_ROCCurveAUC <- AUC(OD_IF_PredictedScores, Status))

```

###  1.5.2. Extended Isolation Forest (EIF)
|
| **[A]** The Extended Isolation Forest algorithm was implemented only for the <span style="color: #FF0000">PC5</span> and <span style="color: #FF0000">PC7</span> principal component descriptors using the <mark style="background-color: #CCECFF">**isotree**</mark> package.  
|
| **[B]** The algorithm contains 3 hyperparameters:
|      **[B.1]** <span style="color: #FF0000">ndims</span> = number of columns to combine to produce a split held constant at a value of 2
|      **[B.2]** <span style="color: #FF0000">ntrees</span> = number of binary trees to build for the model held constant at a value of 100.
|      **[B.3]** <span style="color: #FF0000">missing_action</span> = method of handling missing data at both fitting and prediction time held constant at a value of "FAIL".
|
| **[C]** Using the label information from the <span style="color: #FF0000">Status</span> variable defined prior to the analysis, the algorithm was able to sufficiently discriminate between <span style="color: #FF0000">Status=Outlier</span> and <span style="color: #FF0000">Status=Valid</span>, as demonstrated by their differentially expressed deviance score densities.
|      **[C.1]** ROC Curve AUC = 0.74786
|
```{r section_1.5.2, warning=FALSE, message=FALSE}
##################################
# Implementing the EIF Algorithm
##################################
OD_EIF <- isolation.forest(OD, 
                          ndim=2, 
                          ntrees=100, 
                          missing_action="fail")

##################################
# Determining the outlier scores
# for the deviant points
# applied to the entire space range
##################################
OD_EIF_DevianceScores <- predict(OD_EIF, Space_Range)

##################################
# Plotting the heatmap
# for the deviant points
##################################
par(mar = c(2.5,2.2,2,2.5))
Plot_Space_Range(OD_EIF_DevianceScores,
                 "Deviance Scores : Extended Isolation Forest",
                 1.0)

##################################
# Determining the outlier scores
# for the deviant points
# applied to the dataset
##################################
OD_EIF_PredictedScores <- predict(OD_EIF, OD)

##################################
# Exploring the outlier scores
# between the valid and outlier points
##################################
max(OD_EIF_PredictedScores)
min(OD_EIF_PredictedScores)

OD_EIF_Summary <- DR_PCA_SUBSET

OD_EIF_Summary$Scores <- OD_EIF_PredictedScores
OD_EIF_Summary$Label <- rep("EIF", nrow(OD_EIF_Summary))

densityplot( ~ Scores | Label,
            data = OD_EIF_Summary,
            groups = Status,
            xlab = "Deviance Scores",
            ylab = "Density",
            auto.key = list(columns = (length(levels(OD_EIF_Summary$Status)))))

##################################
# Determining the apparent 
# discrimination performance
# of the EIF Algorithm
##################################
Status <- ifelse(OD_EIF_Summary$Status=="Valid",0,1)

(OD_EIF_ROCCurveAUC <- AUC(OD_EIF_PredictedScores, Status))

```

###  1.5.3. Isolation Forest with Split Selection Criterion (SCIFOREST)
|
| **[A]** The Isolation Forest with Split Selection Criterion algorithm was implemented only for the <span style="color: #FF0000">PC5</span> and <span style="color: #FF0000">PC7</span> principal component descriptors using the <mark style="background-color: #CCECFF">**isotree**</mark> package.  
|
| **[B]** The algorithm contains 5 hyperparameters:
|      **[B.1]** <span style="color: #FF0000">ndims</span> = number of columns to combine to produce a split held constant at a value of 2
|      **[B.2]** <span style="color: #FF0000">ntrees</span> = number of binary trees to build for the model held constant at a value of 100.
|      **[B.3]** <span style="color: #FF0000">missing_action</span> = method of handling missing data at both fitting and prediction time held constant at a value of "FAIL".
|      **[B.4]** <span style="color: #FF0000">coefs</span> = method of sampling random coefficients according to a
standard distribution held constant at a value of "NORMAL".
|      **[B.5]** <span style="color: #FF0000">prob_pick_avg_gain</span> = indicates the probability of choosing the threshold on which to split a variable as the threshold that maximizes an averaged standard deviation gain
criterion on the same variable held constant at a value of 1.
|
| **[C]** Using the label information from the <span style="color: #FF0000">Status</span> variable defined prior to the analysis, the algorithm was not able to sufficiently discriminate between <span style="color: #FF0000">Status=Outlier</span> and <span style="color: #FF0000">Status=Valid</span>, as demonstrated by their comparably expressed deviance score densities.
|      **[C.1]** ROC Curve AUC = 0.56143
|
```{r section_1.5.3, warning=FALSE, message=FALSE}
##################################
# Implementing the SCIFOREST Algorithm
##################################
OD_SCIFOREST <- isolation.forest(OD, 
                          ndim=2, 
                          ntrees=100, 
                          missing_action="fail",
                          coefs="normal",
                          prob_pick_avg_gain=1)

##################################
# Determining the outlier scores
# for the deviant points
# applied to the entire space range
##################################
OD_SCIFOREST_DevianceScores <- predict(OD_SCIFOREST, Space_Range)

##################################
# Plotting the heatmap
# for the deviant points
##################################
par(mar = c(2.5,2.2,2,2.5))
Plot_Space_Range(OD_SCIFOREST_DevianceScores,
                 "Deviance Scores : Isolation Forest with Split Selection Criterion",
                 1.0)

##################################
# Determining the outlier scores
# for the deviant points
# applied to the dataset
##################################
OD_SCIFOREST_PredictedScores <- predict(OD_SCIFOREST, OD)

##################################
# Exploring the outlier scores
# between the valid and outlier points
##################################
max(OD_SCIFOREST_PredictedScores)
min(OD_SCIFOREST_PredictedScores)

OD_SCIFOREST_Summary <- DR_PCA_SUBSET

OD_SCIFOREST_Summary$Scores <- OD_SCIFOREST_PredictedScores
OD_SCIFOREST_Summary$Label <- rep("SCIFOREST", nrow(OD_SCIFOREST_Summary))

densityplot( ~ Scores | Label,
            data = OD_SCIFOREST_Summary,
            groups = Status,
            xlab = "Deviance Scores",
            ylab = "Density",
            auto.key = list(columns = (length(levels(OD_SCIFOREST_Summary$Status)))))

##################################
# Determining the apparent 
# discrimination performance
# of the SCIFOREST Algorithm
##################################
Status <- ifelse(OD_SCIFOREST_Summary$Status=="Valid",0,1)

(OD_SCIFOREST_ROCCurveAUC <- AUC(OD_SCIFOREST_PredictedScores, Status))

```

###  1.5.4. Fair-Cut Forest (FCF)
|
| **[A]** The Fair-Cut Forest algorithm was implemented only for the <span style="color: #FF0000">PC5</span> and <span style="color: #FF0000">PC7</span> principal component descriptors using the <mark style="background-color: #CCECFF">**isotree**</mark> package.  
|
| **[B]** The algorithm contains 4 hyperparameters:
|      **[B.1]** <span style="color: #FF0000">ndims</span> = number of columns to combine to produce a split held constant at a value of 2
|      **[B.2]** <span style="color: #FF0000">ntrees</span> = number of binary trees to build for the model held constant at a value of 100.
|      **[B.3]** <span style="color: #FF0000">missing_action</span> = method of handling missing data at both fitting and prediction time held constant at a value of "FAIL".
|      **[B.4]** <span style="color: #FF0000">prob_pick_pooled_gain</span> = indicates the probability of choosing the threshold on which to split a linear combination of variables as the threshold that maximizes a pooled standard deviation gain criterion on the linear combinantion held constant at a value of 1.
|
| **[C]** Using the label information from the <span style="color: #FF0000">Status</span> variable defined prior to the analysis, the algorithm was able to sufficiently discriminate between <span style="color: #FF0000">Status=Outlier</span> and <span style="color: #FF0000">Status=Valid</span>, as demonstrated by their comparably expressed deviance score densities.
|      **[C.1]** ROC Curve AUC = 0.78291
|
```{r section_1.5.4, warning=FALSE, message=FALSE}
##################################
# Implementing the FCF Algorithm
##################################
OD_FCF <- isolation.forest(OD, 
                          ndim=2, 
                          ntrees=100, 
                          missing_action="fail",
                          prob_pick_pooled_gain=1)

##################################
# Determining the outlier scores
# for the deviant points
# applied to the entire space range
##################################
OD_FCF_DevianceScores <- predict(OD_FCF, Space_Range)

##################################
# Plotting the heatmap
# for the deviant points
##################################
par(mar = c(2.5,2.2,2,2.5))
Plot_Space_Range(OD_FCF_DevianceScores,
                 "Deviance Scores : Fair-Cut Forest",
                 1.0)

##################################
# Determining the outlier scores
# for the deviant points
# applied to the dataset
##################################
OD_FCF_PredictedScores <- predict(OD_FCF, OD)

##################################
# Exploring the outlier scores
# between the valid and outlier points
##################################
max(OD_FCF_PredictedScores)
min(OD_FCF_PredictedScores)

OD_FCF_Summary <- DR_PCA_SUBSET

OD_FCF_Summary$Scores <- OD_FCF_PredictedScores
OD_FCF_Summary$Label <- rep("FCF", nrow(OD_FCF_Summary))

densityplot( ~ Scores | Label,
            data = OD_FCF_Summary,
            groups = Status,
            xlab = "Deviance Scores",
            ylab = "Density",
            auto.key = list(columns = (length(levels(OD_FCF_Summary$Status)))))

##################################
# Determining the apparent 
# discrimination performance
# of the FCF Algorithm
##################################
Status <- ifelse(OD_FCF_Summary$Status=="Valid",0,1)

(OD_FCF_ROCCurveAUC <- AUC(OD_FCF_PredictedScores, Status))

```

###  1.5.5. Density Isolation Forest (DIF)
|
| **[A]** The Density Isolation Forest algorithm was implemented only for the <span style="color: #FF0000">PC5</span> and <span style="color: #FF0000">PC7</span> principal component descriptors using the <mark style="background-color: #CCECFF">**isotree**</mark> package.  
|
| **[B]** The algorithm contains 4 hyperparameters:
|      **[B.1]** <span style="color: #FF0000">ndims</span> = number of columns to combine to produce a split held constant at a value of 2
|      **[B.2]** <span style="color: #FF0000">ntrees</span> = number of binary trees to build for the model held constant at a value of 100.
|      **[B.3]** <span style="color: #FF0000">missing_action</span> = method of handling missing data at both fitting and prediction time held constant at a value of "FAIL".
|      **[B.4]** <span style="color: #FF0000">scoring_metric</span> = metric to use for determining outlier scores held constant at a value of "DENSITY".
|
| **[C]** Using the label information from the <span style="color: #FF0000">Status</span> variable defined prior to the analysis, the algorithm was able to sufficiently discriminate between <span style="color: #FF0000">Status=Outlier</span> and <span style="color: #FF0000">Status=Valid</span>, as demonstrated by their comparably expressed deviance score densities.
|      **[C.1]** ROC Curve AUC = 0.77322
|
```{r section_1.5.5, warning=FALSE, message=FALSE}
##################################
# Implementing the DIF Algorithm
##################################
OD_DIF <- isolation.forest(OD, 
                          ndim=2, 
                          ntrees=100, 
                          missing_action="fail",
                          scoring_metric="density",
                          sample_size=256)

##################################
# Determining the outlier scores
# for the deviant points
# applied to the entire space range
##################################
OD_DIF_DevianceScores <- predict(OD_DIF, Space_Range)

##################################
# Plotting the heatmap
# for the deviant points
##################################
par(mar = c(2.5,2.2,2,2.5))
Plot_Space_Range(OD_DIF_DevianceScores,
                 "Deviance Scores : Density Isolation Forest",
                 1.0)

##################################
# Determining the outlier scores
# for the deviant points
# applied to the dataset
##################################
OD_DIF_PredictedScores <- predict(OD_DIF, OD)

##################################
# Exploring the outlier scores
# between the valid and outlier points
##################################
max(OD_DIF_PredictedScores)
min(OD_DIF_PredictedScores)

OD_DIF_Summary <- DR_PCA_SUBSET

OD_DIF_Summary$Scores <- OD_DIF_PredictedScores
OD_DIF_Summary$Label <- rep("DIF", nrow(OD_DIF_Summary))

densityplot( ~ Scores | Label,
            data = OD_DIF_Summary,
            groups = Status,
            xlab = "Deviance Scores",
            ylab = "Density",
            auto.key = list(columns = (length(levels(OD_DIF_Summary$Status)))))

##################################
# Determining the apparent 
# discrimination performance
# of the DIF Algorithm
##################################
Status <- ifelse(OD_DIF_Summary$Status=="Valid",0,1)

(OD_DIF_ROCCurveAUC <- AUC(OD_DIF_PredictedScores, Status))

```

##  1.6 Algorithm Comparison Summary
|
| Algorithm performance comparison:
|
| **[A]** The density-based clustering algorithms applied to the principal component descriptors which were able to sufficiently capture the latent characteristics between the different cancer groups and identify multivariate outliers based on the higher estimated Rand indices and reasonable outlier detection rates are the following :
|      **[A.1]** SNNCLUST : Shared Nearest Neighbor Clustering (<mark style="background-color: #CCECFF">**dbscan**</mark> package)
|             **[A.1.1]** Outlier Detection Rate = 0.40000
|             **[A.2.1]** Rand Index = 0.93115
|      **[A.2]** DBSCAN: Density-Based Spatial Clustering of Applications with Noise (<mark style="background-color: #CCECFF">**dbscan**</mark> package)
|             **[A.2.1]** Outlier Detection Rate = 0.32500
|             **[A.2.2]** Rand Index = 0.83190
|      **[A.3]** OPTICS: Ordering Points to Identify the Clustering Structure (<mark style="background-color: #CCECFF">**dbscan**</mark> package)
|             **[A.3.1]** Outlier Detection Rate = 0.37500
|             **[A.3.2]** Rand Index = 0.82667
|
```{r section_1.5.6, warning=FALSE, message=FALSE}

# ##################################
# # Replotting the cluster plots for PCA-BASE
# ##################################
# CA_PCABASE_ClusterPlot <- cloud(PC1 ~ PC2*PC3 | Algorithm,
#       groups = EDA$Cancer,
#        data = EDA,
#        type = "p",
#        pch = 16,
#        cex = 2,
#        alpha = 0.45,
#        auto.key = list(points = TRUE, space = "top"))
# 
# ##################################
# # Replotting the cluster plots for DBSCAN
# ##################################
# CA_DBSCAN_ClusterPlot <- cloud(PC1 ~ PC2*PC3 | Algorithm,
#       groups = CA_DBSCAN_Summary$DBSCAN_Cluster,
#        data = CA_DBSCAN_Summary,
#        type = "p",
#        pch = 16,
#        cex = 2,
#        alpha = 0.45,
#        auto.key = list(points = TRUE, space = "top"))
# 
# ##################################
# # Replotting the cluster plots for HDBSCAN
# ##################################
# CA_HDBSCAN_ClusterPlot <- cloud(PC1 ~ PC2*PC3 | Algorithm,
#       groups = CA_HDBSCAN_Summary$HDBSCAN_Cluster,
#        data = CA_HDBSCAN_Summary,
#        type = "p",
#        pch = 16,
#        cex = 2,
#        alpha = 0.45,
#        auto.key = list(points = TRUE, space = "top"))
# 
# ##################################
# # Replotting the cluster plots for OPTICS
# ##################################
# CA_OPTICS_ClusterPlot <- cloud(PC1 ~ PC2*PC3 | Algorithm,
#       groups = CA_OPTICS_Summary$OPTICS_Cluster,
#        data = CA_OPTICS_Summary,
#        type = "p",
#        pch = 16,
#        cex = 2,
#        alpha = 0.45,
#        auto.key = list(points = TRUE, space = "top"))
# 
# ##################################
# # Replotting the cluster plots for JPCLUST
# ##################################
# CA_JPCLUST_ClusterPlot <- cloud(PC1 ~ PC2*PC3 | Algorithm,
#       groups = CA_JPCLUST_Summary$JPCLUST_Cluster,
#        data = CA_JPCLUST_Summary,
#        type = "p",
#        pch = 16,
#        cex = 2,
#        alpha = 0.45,
#        auto.key = list(points = TRUE, space = "top"))
# 
# ##################################
# # Replotting the cluster plots for SNNCLUST
# ##################################
# CA_SNNCLUST_ClusterPlot <- cloud(PC1 ~ PC2*PC3 | Algorithm,
#       groups = CA_SNNCLUST_Summary$SNNCLUST_Cluster,
#        data = CA_SNNCLUST_Summary,
#        type = "p",
#        pch = 16,
#        cex = 2,
#        alpha = 0.45,
#        auto.key = list(points = TRUE, space = "top"))
# 
# ####################################################################
# # Consolidating all algorithm performance results
# ####################################################################
# grid.arrange(CA_PCABASE_ClusterPlot,
#              CA_SNNCLUST_ClusterPlot,
#              CA_DBSCAN_ClusterPlot,
#              CA_OPTICS_ClusterPlot,
#              CA_JPCLUST_ClusterPlot,
#              CA_HDBSCAN_ClusterPlot,
#              ncol=3)
# 
# ##################################
# # Consolidating all 
# # outlier detection rates and rand indices
# # for the analysis data
# ##################################
# ClusteringAlgorithm <- c('DBSCAN','HDBSCAN','OPTICS','JPCLUST','SNNCLUST',
#                          'DBSCAN','HDBSCAN','OPTICS','JPCLUST','SNNCLUST')
# 
# Set <- c(rep('Outlier Detection Rate',5),
#          rep('Rand Index',5))
# 
# ClusteringMetrics <- c(CA_DBSCAN_OutlierDetectionRate,
#                        CA_HDBSCAN_OutlierDetectionRate,
#                        CA_OPTICS_OutlierDetectionRate,
#                        CA_JPCLUST_OutlierDetectionRate,
#                        CA_SNNCLUST_OutlierDetectionRate,
#                        CA_DBSCAN_RandIndex,
#                        CA_HDBSCAN_RandIndex,
#                        CA_OPTICS_RandIndex,
#                        CA_JPCLUST_RandIndex,
#                        CA_SNNCLUST_RandIndex)
# 
# ClusteringPeformance_Summary <- as.data.frame(cbind(ClusteringAlgorithm,
#                                                     Set,
#                                                     ClusteringMetrics))
# 
# ClusteringPeformance_Summary$ClusteringMetrics <- as.numeric(as.character(ClusteringPeformance_Summary$ClusteringMetrics))
# ClusteringPeformance_Summary$Set <- factor(ClusteringPeformance_Summary$Set,
#                                            levels = c("Outlier Detection Rate",
#                                                       "Rand Index"))
# ClusteringPeformance_Summary$ClusteringAlgorithm <- factor(ClusteringPeformance_Summary$ClusteringAlgorithm,
#                                                       levels = c('DBSCAN',
#                                                                  'HDBSCAN',
#                                                                  'OPTICS',
#                                                                  'JPCLUST',
#                                                                  'SNNCLUST'))
# 
# print(ClusteringPeformance_Summary, row.names=FALSE)
# 
# (ClusteringPeformance_Summary_Plot <- dotplot(ClusteringAlgorithm ~ ClusteringMetrics,
#                           data = ClusteringPeformance_Summary,
#                           groups = Set,
#                           main = "Clustering Algorithm Performance Comparison",
#                           ylab = "Algorithm",
#                           xlab = "Clustering Performance Metrics",
#                           auto.key = list(adj = 1),
#                           type=c("p", "h"),
#                           origin = 0,
#                           alpha = 0.45,
#                           pch = 16,
#                           cex = 2))

```

##  1.7 References
|
| **[Book]** [Applied Predictive Modeling](http://appliedpredictivemodeling.com/) by Max Kuhn and Kjell Johnson
| **[Book]** [An Introduction to Statistical Learning](https://www.statlearning.com/) by Gareth James, Daniela Witten, Trevor Hastie and Rob Tibshirani
| **[Book]** [Multivariate Data Visualization with R](http://lmdvr.r-forge.r-project.org/figures/figures.html) by Deepayan Sarkar
| **[Book]** [Machine Learning](https://bookdown.org/ssjackson300/Machine-Learning-Lecture-Notes/) by Samuel Jackson
| **[Book]** [Data Modeling Methods](https://bookdown.org/larget_jacob/data-modeling-methods/) by Jacob Larget
| **[Book]** [Introduction to R and Statistics](https://saestatsteaching.tech/) by University of Western Australia
| **[Book]** [Feature Engineering and Selection: A Practical Approach for Predictive Models](http://www.feat.engineering/index.html) by Max Kuhn and Kjell Johnson
| **[Book]** [Introduction to Research Methods](https://bookdown.org/ejvanholm/Textbook/) by Eric van Holm
| **[R Package]** [AppliedPredictiveModeling](https://cran.r-project.org/web//packages/AppliedPredictiveModeling/AppliedPredictiveModeling.pdf) by Max Kuhn
| **[R Package]** [caret](https://topepo.github.io/caret/index.html) by Max Kuhn
| **[R Package]** [rpart](https://mran.microsoft.com/web/packages/rpart/rpart.pdf) by Terry Therneau and Beth Atkinson
| **[R Package]** [lattice](https://cran.r-project.org/web/packages/lattice/lattice.pdf) by  Deepayan Sarkar
| **[R Package]** [dplyr](https://cran.r-project.org/web/packages/dplyr/index.html/) by Hadley Wickham
| **[R Package]** [moments](https://cran.r-project.org/web/packages/moments/index.html) by Lukasz Komsta and Frederick
| **[R Package]** [skimr](https://cran.r-project.org/web/packages/skimr/skimr.pdf) by  Elin Waring
| **[R Package]** [RANN](https://cran.r-project.org/web/packages/RANN/RANN.pdf) by  Sunil Arya, David Mount, Samuel Kemp and Gregory Jefferis
| **[R Package]** [corrplot](https://cran.r-project.org/web/packages/corrplot/corrplot.pdf) by Taiyun Wei
| **[R Package]** [tidyverse](https://cran.r-project.org/web/packages/tidyverse/tidyverse.pdf) by Hadley Wickham
| **[R Package]** [lares](https://cran.rstudio.com/web/packages/lares/lares.pdf) by Bernardo Lares
| **[R Package]** [DMwR](https://mran.microsoft.com/snapshot/2016-05-02/web/packages/DMwR/DMwR.pdf) by Luis Torgo
| **[R Package]** [gridExtra](https://cran.r-project.org/web/packages/gridExtra/gridExtra.pdf) by Baptiste Auguie and Anton Antonov
| **[R Package]** [rattle](https://cran.r-project.org/web/packages/rattle/rattle.pdf) by Graham Williams
| **[R Package]** [RColorBrewer](https://cran.r-project.org/web//packages/RColorBrewer/RColorBrewer.pdf) by Erich Neuwirth
| **[R Package]** [stats](https://search.r-project.org/R/refmans/stats/html/00Index.html) by R Core Team
| **[R Package]** [ISLR](https://cran.r-project.org/web/packages/ISLR/ISLR.pdf) by Trevor Hastie
| **[R Package]** [factoextra](https://cran.r-project.org/web/packages/factoextra/factoextra.pdf) by Alboukadel Kassambara
| **[R Package]** [NbClust](https://cran.r-project.org/web/packages/NbClust/NbClust.pdf) by Malika Charrad, Nadia Ghazzali, Veronique Boiteau and Azam Niknafs
| **[R Package]** [cluster](https://cran.r-project.org/web/packages/cluster/cluster.pdf) by Martin Maechler
| **[R Package]** [dbscan](https://cran.r-project.org/web/packages/dbscan/dbscan.pdf) by Michael Hahsler
| **[R Package]** [fossil](https://cran.r-project.org/web/packages/fossil/fossil.pdf) by Matthew Vavrek
| **[Article]** [Cluster Analysis in R Simplified and Enhanced](https://www.datanovia.com/en/blog/cluster-analysis-in-r-simplified-and-enhanced/) by Datanovia Team
| **[Article]** [Cluster Validation Essentials](http://www.sthda.com/english/articles/29-cluster-validation-essentials/96-determiningthe-optimal-number-of-clusters-3-must-know-methods/) by Alboukadel Kassambara
| **[Article]** [Data Preparation and R Packages for Cluster Analysis](https://www.datanovia.com/en/lessons/data-preparation-and-r-packages-for-cluster-analysis/) by Datanovia Team
| **[Article]** [The Complete Guide to Clustering Analysis: K-Means and Hierarchical Clustering by Hand and in R](https://statsandr.com/blog/clustering-analysis-k-means-and-hierarchical-clustering-by-hand-and-in-r/#silhouette-method) by Antoine Soetewey
| **[Article]** [Clustering](https://scikit-learn.org/stable/modules/clustering.html) by Scikit-Learn Team
| **[Article]** [Practical Guide to Clustering Algorithms & Evaluation in R](https://www.hackerearth.com/practice/machine-learning/machine-learning-algorithms/clustering-algorithms-evaluation-r/tutorial/) by Hacker Earth Team
| **[Article]** [Measures for Comparing Clustering Algorithms](https://www.datanovia.com/en/lessons/choosing-the-best-clustering-algorithms/#:~:text=Compare%20clustering%20algorithms%20in%20R%20We%E2%80%99ll%20use%20the,%22average%22%29%20obj%3A%20A%20numeric%20matrix%20or%20data%20frame.) by Datanovia Team
| **[Article]** [DBSCAN Algorithm | How Does It Work?](https://www.mygreatlearning.com/blog/dbscan-algorithm/) by Pavan Kumar Raja
| **[Article]** [DBSCAN Clustering in ML | Density Based Clustering](https://www.geeksforgeeks.org/dbscan-clustering-in-ml-density-based-clustering/) by Geeks For Geeks Team
| **[Article]** [Density-Based Spatial Clustering of Applications with Noise (DBSCAN)](https://ml-explained.com/blog/dbscan-explained) by Machine Learning Explained Team
| **[Article]** [Visualizing DBSCAN Clustering](https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/) by Naftali Harris 
| **[Article]** [Demo of OPTICS Clustering Algorithm](https://scikit-learn.org/stable/auto_examples/cluster/plot_optics.html) by Scikit-Learn Team
| **[Article]** [ML | OPTICS Clustering Explanation](https://www.geeksforgeeks.org/ml-optics-clustering-explanation/) by Geeks For Geeks Team
| **[Article]** [Comparing Different Clustering Algorithms on Toy Datasets](xxx) by Scikit-Learn Team
| **[Article]** [How HDBSCAN Works](https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html) by HDBSCAN Team
| **[Article]** [Understanding HDBSCAN and Density-Based Clustering](https://pberba.github.io/stats/2020/01/17/hdbscan/) by Pepe Berba
| **[Article]** [SNN Clustering](http://mlwiki.org/index.php/SNN_Clustering) by Alexey Grigorev
| **[Article]** [Basic Understanding of Jarvis-Patrick Clustering Algorithm](https://www.geeksforgeeks.org/basic-understanding-of-jarvis-patrick-clustering-algorithm/) by Geeks For Geeks Team
| **[Article]** [Jarvis-Patrick Clustering](https://docs.chemaxon.com/display/docs/jarvis-patrick-clustering.md) by Chemaxon Team
| **[Article]** [Which Are The Best Clustering Metrics? (Explained Simply)](https://stephenallwright.com/good-clustering-metrics/) by Stephen Allwright
| **[Article]** [Elbow Method vs Silhouette Score  Which is Better?](https://vitalflux.com/elbow-method-silhouette-score-which-better/) by Ajitesh Kumar
| **[Article]** [Assessment Metrics for Clustering Algorithms](https://opendatascience.com/assessment-metrics-clustering-algorithms/) by Spencer Norris
| **[Article]** [Clustering Performance Evaluation in Scikit Learn](https://www.geeksforgeeks.org/clustering-performance-evaluation-in-scikit-learn/) by Geeks For Geeks Team
| **[Article]** [Taxonomy of Data Clustering Methods](https://1library.net/article/taxonomy-data-clustering-methods-overview-data-clustering-tools.y8p5nn4z) by Yun Lillian Li
| **[Publication]** [Finding Clusters of Different Sizes, Shapes, and Densities in Noisy, High Dimensional Data](https://epubs.siam.org/doi/10.1137/1.9781611972733.5) by Levent Ertz, Michael Steinbach, and Vipin Kumar (Proceedings of the 2003 SIAM International Conference on Data Mining)
| **[Course]** [Applied Data Mining and Statistical Learning](https://online.stat.psu.edu/stat508/) by Penn State Eberly College of Science
|
|
|
|